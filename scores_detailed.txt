Multinomial Naive Bayes TF IDF: Tuning hyper-parameters
Grid scores on development set:
0.456 (+/-0.095) for {'naiveBayes__class_prior': [0.3, 0.7], 'selector__key': 'buggy', 'selector__window_size': 11}
0.464 (+/-0.088) for {'naiveBayes__class_prior': [0.3, 0.7], 'selector__key': 'buggy', 'selector__window_size': 21}
0.481 (+/-0.102) for {'naiveBayes__class_prior': [0.3, 0.7], 'selector__key': 'buggy', 'selector__window_size': 51}
0.385 (+/-0.086) for {'naiveBayes__class_prior': [0.3, 0.7], 'selector__key': 'fixed', 'selector__window_size': 11}
0.385 (+/-0.088) for {'naiveBayes__class_prior': [0.3, 0.7], 'selector__key': 'fixed', 'selector__window_size': 21}
0.387 (+/-0.091) for {'naiveBayes__class_prior': [0.3, 0.7], 'selector__key': 'fixed', 'selector__window_size': 51}

Classification report:
              precision    recall  f1-score   support

           0       1.00      0.38      0.55       878
           1       0.01      1.00      0.03         7

   micro avg       0.39      0.39      0.39       885
   macro avg       0.51      0.69      0.29       885
weighted avg       0.99      0.39      0.55       885


Confusion matrix:
[[335 543]
 [  0   7]]

Accuracy Score:
0.3864406779661017

<Receiver Operating Characteristic Plot>



Multinomial Naive Bayes Counts: Tuning hyper-parameters
Grid scores on development set:
0.809 (+/-0.060) for {'naiveBayes__class_prior': [0.3, 0.7], 'selector__key': 'buggy', 'selector__window_size': 11}
0.801 (+/-0.058) for {'naiveBayes__class_prior': [0.3, 0.7], 'selector__key': 'buggy', 'selector__window_size': 21}
0.806 (+/-0.059) for {'naiveBayes__class_prior': [0.3, 0.7], 'selector__key': 'buggy', 'selector__window_size': 51}
0.675 (+/-0.080) for {'naiveBayes__class_prior': [0.3, 0.7], 'selector__key': 'fixed', 'selector__window_size': 11}
0.672 (+/-0.085) for {'naiveBayes__class_prior': [0.3, 0.7], 'selector__key': 'fixed', 'selector__window_size': 21}
0.672 (+/-0.082) for {'naiveBayes__class_prior': [0.3, 0.7], 'selector__key': 'fixed', 'selector__window_size': 51}

Classification report:
              precision    recall  f1-score   support

           0       1.00      0.80      0.89       881
           1       0.01      0.50      0.02         4

   micro avg       0.80      0.80      0.80       885
   macro avg       0.50      0.65      0.45       885
weighted avg       0.99      0.80      0.88       885


Confusion matrix:
[[705 176]
 [  2   2]]

Accuracy Score:
0.7988700564971751

<Receiver Operating Characteristic Plot>



Decision Tree: Tuning hyper-parameters
Grid scores on development set:
0.988 (+/-0.017) for {'selector__key': 'buggy', 'selector__window_size': 11}
0.988 (+/-0.015) for {'selector__key': 'buggy', 'selector__window_size': 21}
0.987 (+/-0.013) for {'selector__key': 'buggy', 'selector__window_size': 51}
0.990 (+/-0.007) for {'selector__key': 'fixed', 'selector__window_size': 11}
0.990 (+/-0.007) for {'selector__key': 'fixed', 'selector__window_size': 21}
0.987 (+/-0.012) for {'selector__key': 'fixed', 'selector__window_size': 51}

Classification report:
              precision    recall  f1-score   support

           0       1.00      0.99      0.99       877
           1       0.44      0.50      0.47         8

   micro avg       0.99      0.99      0.99       885
   macro avg       0.72      0.75      0.73       885
weighted avg       0.99      0.99      0.99       885


Confusion matrix:
[[872   5]
 [  4   4]]

Accuracy Score:
0.9898305084745763

<Receiver Operating Characteristic Plot>



Support Vector Classifier: Tuning hyper-parameters
Grid scores on development set:
0.837 (+/-0.058) for {'selector__key': 'buggy', 'selector__window_size': 11}
0.834 (+/-0.054) for {'selector__key': 'buggy', 'selector__window_size': 21}
0.839 (+/-0.058) for {'selector__key': 'buggy', 'selector__window_size': 51}
0.768 (+/-0.036) for {'selector__key': 'fixed', 'selector__window_size': 11}
0.772 (+/-0.036) for {'selector__key': 'fixed', 'selector__window_size': 21}
0.769 (+/-0.046) for {'selector__key': 'fixed', 'selector__window_size': 51}
Warnings during grid search:
{
    "<class 'FutureWarning'>": 61
}

Classification report:
              precision    recall  f1-score   support

           0       1.00      0.83      0.91       878
           1       0.03      0.71      0.06         7

   micro avg       0.83      0.83      0.83       885
   macro avg       0.51      0.77      0.48       885
weighted avg       0.99      0.83      0.90       885


Confusion matrix:
[[728 150]
 [  2   5]]

Accuracy Score:
0.8282485875706215



Logistic Regression Operator: Tuning hyper-parameters
Grid scores on development set:
0.902 (+/-0.033) for {'union__bytecodes__selector__window_size': 11}
0.903 (+/-0.033) for {'union__bytecodes__selector__window_size': 21}
0.903 (+/-0.032) for {'union__bytecodes__selector__window_size': 51}
Warnings during grid search:
{
    "<class 'FutureWarning'>": 31
}

Classification report:
              precision    recall  f1-score   support

           0       1.00      0.91      0.95       875
           1       0.09      0.80      0.16        10

   micro avg       0.91      0.91      0.91       885
   macro avg       0.54      0.85      0.56       885
weighted avg       0.99      0.91      0.94       885


Confusion matrix:
[[796  79]
 [  2   8]]

Accuracy Score:
0.9084745762711864

<Receiver Operating Characteristic Plot>



Logistic Regression PCA: Tuning hyper-parameters
Grid scores on development set:
0.797 (+/-0.057) for {'selector__window_size': 11}
0.799 (+/-0.045) for {'selector__window_size': 21}
0.796 (+/-0.054) for {'selector__window_size': 51}
Warnings during grid search:
{
    "<class 'FutureWarning'>": 31
}

Classification report:
              precision    recall  f1-score   support

           0       1.00      0.77      0.87       875
           1       0.04      0.80      0.07        10

   micro avg       0.77      0.77      0.77       885
   macro avg       0.52      0.79      0.47       885
weighted avg       0.99      0.77      0.86       885


Confusion matrix:
[[675 200]
 [  2   8]]

Accuracy Score:
0.7717514124293785

<Receiver Operating Characteristic Plot>



Logistic Regression: Tuning hyper-parameters
Grid scores on development set:
0.897 (+/-0.043) for {'selector__window_size': 11}
0.902 (+/-0.048) for {'selector__window_size': 21}
0.902 (+/-0.050) for {'selector__window_size': 51}
Warnings during grid search:
{
    "<class 'FutureWarning'>": 31
}

Classification report:
              precision    recall  f1-score   support

           0       1.00      0.91      0.95       878
           1       0.07      0.86      0.13         7

   micro avg       0.91      0.91      0.91       885
   macro avg       0.53      0.88      0.54       885
weighted avg       0.99      0.91      0.95       885


Confusion matrix:
[[799  79]
 [  1   6]]

Accuracy Score:
0.9096045197740112



TorchRecurrentLabeled: Tuning hyper-parameters
Classification report:
              precision    recall  f1-score   support

           0       0.00      0.00      0.00       877
           1       0.01      1.00      0.02         8

   micro avg       0.01      0.01      0.01       885
   macro avg       0.00      0.50      0.01       885
weighted avg       0.00      0.01      0.00       885


Confusion matrix:
[[  0 877]
 [  0   8]]

Accuracy Score:
0.00903954802259887

<Receiver Operating Characteristic Plot>
